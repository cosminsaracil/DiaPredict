Cell 1: Environment Setup and Data Loading

    Setting up the environment. It imports essential Python libraries required for data analysis, manipulation, and visualization, ensuring that all necessary tools are available for subsequent steps in your pipeline.
    Verifying the environment. It prints details about the Python environment, such as the executable path, version, and site packages, which helps confirm that the correct environment is being used—a useful check for reproducibility or debugging.
    Loading the dataset: It specifies the path to a CSV file containing diabetes-related data, checks if the file exists, and loads it into a pandas DataFrame for further processing. It also provides a quick preview of the data by displaying column names and the first few rows.

    Important note. The data is loaded locally because of the nature of the dataset. If you plan to use this code make sure to make a copy of the dataset available on Kaggle.

Cell 4: Distribution of data

    Designed to check the frequency of values in various columns of your (df). This cell is a key part of Exploratory Data Analysis (EDA), helping you visualize how data is distributed across different features.
    Generates a grid of histograms, one for each feature in your (df) (except 'stroke'). A histogram shows how often different values or ranges of values appear in a column. For example:

    If a feature like “age” has a histogram with a peak at 40, it means many people in your dataset are around 40 years old.
    If a categorical feature like “gender” has two bars (e.g., for “Male” and “Female”), it shows how many entries fall into each category.

Cell 5: Correlation between any features

    The cell aims to visualize how each feature in your dataset relates to the target variable, 'Diabetes'.
    By default, it uses Pearson correlation, which measures the strength and direction of the linear relationship between two variables. The output is a Series where each index is a column name from df, and each value is the correlation coefficient (ranging from -1 to 1) with 'Diabetes'.

    Features with high positive (close to 1) or negative (close to -1) correlations are likely more relevant for predicting 'Diabetes'.
    Features with correlations near zero may have little linear relationship with the target and could potentially be dropped to simplify your model.

    Positive correlations mean that as the feature value increases, 'Diabetes' tends to increase (e.g., higher age might correlate with higher diabetes risk).
    Negative correlations suggest the opposite (e.g., higher physical activity might reduce diabetes likelihood).

    While this plot focuses on the target, it’s a reminder to check for multicollinearity (high correlations between features) later, as it can affect models like linear regression.

Cell 6: Heatmap

    Creates a correlation heatmap for df.
    cmap='coolwarm': Applies the “coolwarm” color scheme—blue for negative correlations, red for positive ones, and neutral colors near zero.
    Rows and columns correspond to the features (columns) in df.
    Each cell’s color and number represent the correlation between the row and column features.

    Spotting multicollinearity:

    High correlations (e.g., above 0.8 or below -0.8) between features suggest redundancy. This can affect machine learning models like linear regression by causing overfitting or unstable predictions.

    Understanding relationships:

    It reveals how features relate to each other and to the target variable (if included in df). For example, in a diabetes dataset, you might see BMI and weight strongly correlated, which aligns with real-world expectations.

    Reading: 
        Diagonal: Cells where a feature correlates with itself (e.g., “Age” vs. “Age”) will show 1 (bright red), since they’re perfectly correlated.
        Target Correlations: “Diabetes” is the target so its row or column shows how each feature correlates with it—useful for identifying key predictors.
        Feature Pairs: Off-diagonal cells show relationships between different features. 
        For example:
        “Age” vs. “BMI” = 0.6 (red): As age increases, BMI tends to increase.
        “Exercise” vs. “BMI” = -0.4 (blue): More exercise is associated with lower BMI.

            Color Guide:

            Red: Positive correlation (features move together).
            Blue: Negative correlation (features move oppositely).
            White/Pale: Little to no correlation.

Cell 9: Data splitting
    
    Prepares the dataset for training and evaluating a machine learning model by splitting it into training and testing sets.
    Defining the target variable (y)
        y = (df['Diabetes']).astype(int): This extracts the 'Diabetes' column from (df) and converts it to integers. This column is your target variable—what you aim to predict (e.g., 0 for no diabetes, 1 for diabetes).
    Defining the Feature Variables (X)
        X = df.loc[:, df.columns != 'Diabetes']: This selects all columns in df except 'Diabetes'. These are your features—the inputs your model will use to make predictions.

    X_train, y_train: Training features and target (80% of the data).
    X_test, y_test: Testing features and target (20% of the data).

Cell 10 : Hyperparameter tunning 

    Hyperparameter Tuning: Testing different combinations of parameters to improve results.
    K-Folds Cross-Validation: The cv=5 in GridSearchCV implements 5-fold cross-validation. 
    Random Seeding: random_state=42 ensures reproducibility, aligning with the need for random seeding in splits.

Cell 11: Ablation testing

    Purpose: This cell performs ablation testing by varying the max_depth parameter of a Decision Tree Classifier (1, 3, 5, 7, unlimited) to see how tree depth impacts performance.
    Process: For each depth, it trains a new model on X_train and y_train, predicts on X_test, computes accuracy, and stores/results are printed.
    Output: Accuracy scores for each depth, e.g., Max Depth: 3, Test Accuracy: 0.7200.
    This cell isolates max_depth and tests it systematically (including 1 and None) on the test set (X_test), not cross-validation. It’s ablation testing, focusing on understanding the specific effect of depth alone, holding other parameters constant (criterion='gini', defaults for others).

    NOTE The variable clf is redefined in each loop iteration with a new DecisionTreeClassifier instance. After the loop ends, clf holds the last model (depth=None), but this doesn’t affect clf_gini from your previous hyperparameter tuning cell (where clf_gini was set to the best model with max_depth=7).
    NOTE Key Point: This cell doesn’t update clf_gini—it’s just testing different depths and printing results. The main model (clf_gini) remains unchanged unless you explicitly reassign it.

Cell 14: Scalability testing

    Purpose: Performs scalability testing by measuring how training time varies with dataset size and tree depth.
    Process: 
        Subsamples X_train and y_train at fractions (25%, 50%, 75%, 100%).
        Tests tree depths (3, 5, 10).
        Times the fit operation for each combination and prints the results.
    Output: Shows training time (in seconds) for each size-depth pair, e.g., Data Fraction: 0.5, Depth: 5, Time: 0.0123 seconds.

    Scalability Testing: Fully satisfies this requirement by computing execution time with respect to dataset size (simulating batch size) and tree depth (model complexity). Decision trees don’t use epochs or convergence in the traditional sense, so this adapts well to the algorithm.

    Small Data, Shallow Tree: Fastest (0.0121s at 25%, Depth 3).
    Full Data, Deep Tree: Slowest (0.1502s at 100%, Depth 10)—~12x slower than the fastest.
    Pattern: Time grows roughly linearly with data size and slightly more with depth due to increased complexity.

    Key Insights

    Scalability: Your Decision Tree scales reasonably—training is fast (<0.2s) even with full data and depth 10, typical for small-to-medium datasets.
    Trade-Off: Deeper trees (e.g., 7, your tuned depth) take longer but might improve accuracy (from ablation). Balance time vs. performance.
    Practicality: Times are low, so scalability isn’t a bottleneck here, but this confirms deeper models and more data demand more computation.
    Confirm 7 depth.

Cell 15 : K-Folds Cross-Validation

    Purpose: Implements stratified k-folds cross-validation with 10 runs to evaluate the tuned Decision Tree model, computing multiple metrics and their mean/std.
    Process:

        Loops over 10 seeds (different random splits).
        For each seed, performs 5-fold stratified cross-validation on X and y.
        Within each fold, splits the training data into 90% train and 10% validation.
        Trains on the 90% subset (X_train_sub, y_train_sub) and predicts on the test fold (X_test_fold).
        Collects accuracy, precision, recall, and F1-score, then computes mean and std.

    Output: Prints mean and standard deviation for each metric across 50 evaluations (10 runs × 5 folds).

    Accuracy

        Definition: The proportion of correct predictions (both true positives and true negatives) out of all predictions.
        Formula: (TP + TN) / (TP + TN + FP + FN), where TP = true positives, TN = true negatives, FP = false positives, FN = false negatives.
        Output: Accuracy - Mean: 0.7405, Std: 0.0037
            Mean (0.7405): On average, your model correctly predicts diabetes status 74.05% of the time across 50 evaluations (10 runs × 5 folds).
            Std (0.0037): The accuracy varies by only ±0.37% across runs, indicating high stability.
    Precision

        Definition: The proportion of predicted positives (1s) that are actually positive. It measures how reliable a positive prediction is.
        Formula: TP / (TP + FP).
        Your Output: Precision - Mean: 0.7222, Std: 0.0088
            Mean (0.7222): When your model predicts diabetes (1), it’s correct 72.22% of the time. About 28% of positive predictions are false positives.
            Std (0.0088): Precision varies by ±0.88%, showing consistent performance.
    Recall (Sensitivity)

        Definition: The proportion of actual positives (1s) that are correctly predicted. It measures how well the model catches all positive cases.
        Formula: TP / (TP + FN).
        Your Output: Recall - Mean: 0.7825, Std: 0.0171
            Mean (0.7825): The model identifies 78.25% of actual diabetes cases, missing about 22% (false negatives).
            Std (0.0171): Recall fluctuates by ±1.71%, suggesting slightly more variability than other metrics.

    F1-Score

        Definition: The harmonic mean of precision and recall, balancing the trade-off between them. It’s useful when classes are imbalanced.
        Formula: 2 * (Precision * Recall) / (Precision + Recall).
        Your Output: F1 - Mean: 0.7509, Std: 0.0047
            Mean (0.7509): An F1 of 75.09% reflects a good balance between precision (72.22%) and recall (78.25%).
            Std (0.0047): F1 varies by ±0.47%, indicating stable performance.

Cell 16: Evaluation metrics

    Purpose: Evaluates the tuned Decision Tree model (clf_gini) on the initial test set (X_test) by computing standard classification metrics and a confusion matrix.
    Process:

        Predicts labels for X_test using clf_gini (from hyperparameter tuning).
        Prints a classification report (accuracy, precision, recall, F1 per class).
        Prints a confusion matrix (TP, FN, FP, TN).

            Classification Report:
                    precision    recall  f1-score   support
    No Diabetes       0.77      0.69      0.73      7090
    Diabetes          0.72      0.79      0.75      7049
    accuracy                              0.74     14139
    macro avg         0.74      0.74      0.74     14139
    weighted avg      0.74      0.74      0.74     14139

    Key Terms

    Support: Number of true instances per class in the test set.
    Precision: How many predicted positives are actually positive.
    Recall: How many actual positives are correctly predicted.
    F1-Score: Harmonic mean of precision and recall.
    Accuracy: Overall proportion of correct predictions.

        Classification Report Breakdown

    No Diabetes (Class 0)
        Precision: 0.77: Of all instances predicted as “No Diabetes,” 77% were correct. 23% were falsely predicted as negative (false negatives misclassified as positives).
        Recall: 0.69: Of all actual “No Diabetes” cases (7090), 69% were correctly identified. 31% were missed (false positives).
        F1-Score: 0.73: Balances precision and recall — slightly favoring precision.
        Support: 7090: Number of true “No Diabetes” cases in the test set.
    Diabetes (Class 1)
        Precision: 0.72: Of all instances predicted as “Diabetes,” 72% were correct. 28% were falsely predicted as positive (false positives).
        Recall: 0.79: Of all actual “Diabetes” cases (7049), 79% were correctly identified. 21% were missed (false negatives).
        F1-Score: 0.75: Good balance, slightly favoring recall.
        Support: 7049: Number of true “Diabetes” cases in the test set.
    Accuracy: 0.74
        74% of all predictions (14,139 total) were correct. Matches k-folds mean (0.7405), showing consistency.
    Macro Avg: 0.74
        Average of precision, recall, and F1 across classes, unweighted by support. Equal performance across both classes.
    Weighted Avg: 0.74
        Same as macro avg here due to nearly balanced classes (7090 vs. 7049).


         Confusion Matrix:
            [[4875 2215]
            [1483 5566]]
        Rows: True labels (0 = No Diabetes, 1 = Diabetes).
        Columns: Predicted labels (0 = No Diabetes, 1 = Diabetes).
        [[4875 2215]] (No Diabetes row):
            4875 (True Negatives, TN): Correctly predicted as “No Diabetes.”
            2215 (False Positives, FP): Incorrectly predicted as “Diabetes.”
        [1483 5566] (Diabetes row):
            1483 (False Negatives, FN): Incorrectly predicted as “No Diabetes.”
            5566 (True Positives, TP): Correctly predicted as “Diabetes.”

        Quick Calculations

            Total: 4875 + 2215 + 1483 + 5566 = 14,139 (matches support sum).
            Accuracy: (TN + TP) / Total = (4875 + 5566) / 14139 ≈ 0.74 (matches report).
            Class 0 Recall: TN / (TN + FP) = 4875 / 7090 ≈ 0.69 (matches).
            Class 1 Recall: TP / (TP + FN) = 5566 / 7049 ≈ 0.79 (matches)

        Interpretation

            Overall Performance
                74% Accuracy: consistent with your k-folds (0.7405 mean). It’s correctly classifying 3 out of 4 cases.
            Class Balance
                Nearly equal support (7090 vs. 7049) means the dataset is balanced, so accuracy is a fair metric here.
            Strengths
                High Recall for Diabetes (0.79): Catches 79% of diabetes cases—good for a medical task where missing cases (FN) is costly.
                Decent Precision for No Diabetes (0.77): Reliable when ruling out diabetes.
            Weaknesses
                Lower Recall for No Diabetes (0.69): Misses 31% of non-diabetes cases (2215 FP), potentially over-diagnosing.
                Moderate Precision for Diabetes (0.72): 28% of diabetes predictions are wrong (1483 FN).
            Trade-Offs
                The model prioritizes recall for Diabetes (0.79) over precision (0.72), reducing missed cases at the cost of more false positives. 


Cell 17: State of art

            Purpose: Compares tuned Decision Tree (clf_gini) with a Random Forest Classifier, a stronger model, on the test set.
            Process:
                Trains a Random Forest with 100 trees (n_estimators=100) on X_train, y_train.
                Predicts on X_test and compares accuracy with the Decision Tree’s predictions (y_pred_gini).

        “State-of-the-art” (SOTA) refers to the best-performing models or techniques currently available for a specific task, based on research or practical benchmarks.
        Context: For tabular data classification (like diabetes prediction), Random Forest, Gradient Boosting (e.g., XGBoost), or neural networks are often SOTA. Random Forest is a practical choice here due to its strength and ease of use.

        Random Forest is an ensemble method that builds multiple decision trees (here, 100) and combines their predictions (e.g., majority voting for classification). It reduces overfitting and improves accuracy over a single tree.
        Accuracy: The proportion of correct predictions on X_test. In your cell, it’s computed as accuracy_score(y_test, y_pred_rf)—e.g., if it’s 0.80, Random Forest correctly predicts 80% of test cases.

        Benchmarking (Req 5): Comparing  Decision Tree (74% accuracy) with a SOTA model like Random Forest shows how close the model is to top performance. If Random Forest gets, say, 80%, it sets a higher bar and highlights potential improvement.
        Improvement Insight: Random Forest often outperforms single trees due to ensemble averaging, so a gap (e.g., 74% vs. 80%) suggests your model could be enhanced (e.g., by switching to  RF or tuning further).
        Justification: Demonstrates your model’s competitiveness or limitations, a key part of ML evaluation.


        Decision Tree Accuracy: 0.7395 (~73.95%)

        What It Means: The tuned Decision Tree correctly predicts diabetes status for 73.95% of the test set (14,139 samples).
        Interpretation: This aligns well with your earlier results:
            K-Folds mean: 0.7405.
            Previous test set eval: 0.74.

        Random Forest Accuracy: 0.7232 (~72.32%)

        What It Means: The Random Forest (n_estimators=100) correctly predicts 72.32% of the test set.
        Interpretation: Slightly lower than the Decision Tree, which is unexpected since Random Forest typically outperforms single trees.
                Possible Reasons:
                    Tuning: Your Decision Tree is well-tuned (max_depth=7, etc.), while Random Forest uses default parameters except n_estimators=100. Untuned Random Forest might underperform.
                    Dataset Fit: Your data might suit a single, tuned tree better (e.g., simple patterns), or the test set aligns closely with the Decision Tree’s splits.
